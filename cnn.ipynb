{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+vbPrVFyuf6aNdpE1EXKK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexlinapp/python_tools_practice/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJLo2dPcz1nx",
        "outputId": "8367bea2-398d-4956-cfa9-490a84d652f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3pCCg4c9MTw",
        "outputId": "468ddf0b-791b-4294-b869-06a65d4ac11c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from fastai.vision.all import *\n",
        "from torchinfo import summary\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Download and load MNIST training data\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Download and load MNIST test data\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfty6PLw-Uje",
        "outputId": "164ece1b-04d6-46a4-f6a4-cc2952a77053"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.43MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.24MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
        "xb, yb = next(iter(dls))\n",
        "xb = xb.view(64, -1, 28, 28)\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76pcfq7Y-XEn",
        "outputId": "ee143d58-9308-486a-c3a1-92ef08f34e46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_edge = torch.tensor([[-1,-1,-1], [0,0,0], [1,1,1]]).float()\n",
        "bottom_edge = torch.tensor([[1,1,1], [0,0,0], [-1,-1,-1]]).float()\n",
        "edge_kernels = torch.stack([top_edge, bottom_edge]).unsqueeze(1)\n",
        "#show_image(xb[59].view(-1, 28))\n",
        "batch_features = F.conv2d(xb.view(-1, 1, 28, 28), edge_kernels, stride=1, padding=1)\n",
        "show_image(batch_features[59][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "3QV_LxcQ9RB3",
        "outputId": "de9bd5b0-0020-4108-932d-66fdaa1c260a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "broken_cnn = sequential(\n",
        "    nn.Conv2d(1,30, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(30,1, kernel_size=3, padding=1)\n",
        ")\n",
        "broken_cnn(xb).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSj9mGJldiS",
        "outputId": "8b8e53d2-c636-465e-de83-b410659774ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(ni, nf, ks=3, act=True):\n",
        "  res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n",
        "  if act: res = nn.Sequential(res, nn.ReLU())\n",
        "  return res"
      ],
      "metadata": {
        "id": "XdJZ82aMuxSJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_cnn = sequential(\n",
        "    conv(1 ,4),            #14x14\n",
        "    conv(4 ,8),            #7x7\n",
        "    conv(8 ,16),           #4x4\n",
        "    conv(16,32),           #2x2\n",
        "    conv(32,10, act=False), #1x1\n",
        "    Flatten(),\n",
        ")\n",
        "simple_cnn(xb).shape\n",
        "summary(simple_cnn, input_size=(64, 1, 28, 28))#, simple_cnn(xb).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbF3AZDIyknX",
        "outputId": "363d4a89-7025-4a25-cfea-ce0d156912ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential                               [64, 10]                  --\n",
              "├─Sequential: 1-1                        [64, 4, 14, 14]           --\n",
              "│    └─Conv2d: 2-1                       [64, 4, 14, 14]           40\n",
              "│    └─ReLU: 2-2                         [64, 4, 14, 14]           --\n",
              "├─Sequential: 1-2                        [64, 8, 7, 7]             --\n",
              "│    └─Conv2d: 2-3                       [64, 8, 7, 7]             296\n",
              "│    └─ReLU: 2-4                         [64, 8, 7, 7]             --\n",
              "├─Sequential: 1-3                        [64, 16, 4, 4]            --\n",
              "│    └─Conv2d: 2-5                       [64, 16, 4, 4]            1,168\n",
              "│    └─ReLU: 2-6                         [64, 16, 4, 4]            --\n",
              "├─Sequential: 1-4                        [64, 32, 2, 2]            --\n",
              "│    └─Conv2d: 2-7                       [64, 32, 2, 2]            4,640\n",
              "│    └─ReLU: 2-8                         [64, 32, 2, 2]            --\n",
              "├─Conv2d: 1-5                            [64, 10, 1, 1]            2,890\n",
              "├─Flatten: 1-6                           [64, 10]                  --\n",
              "==========================================================================================\n",
              "Total params: 9,034\n",
              "Trainable params: 9,034\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 4.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 0.80\n",
              "Params size (MB): 0.04\n",
              "Estimated Total Size (MB): 1.04\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, epochs=4, device=\"cpu\"):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    for xb, yb in DataLoader(mnist_train, batch_size=64, shuffle=True):\n",
        "      optimizer.zero_grad()\n",
        "      xb = xb.to(device)\n",
        "      yb = yb.to(device)\n",
        "      preds = model(xb)\n",
        "      loss = F.cross_entropy(preds, yb)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      correct += (preds.argmax(dim=1) == yb).sum().item()\n",
        "      train_loss += loss.item() * xb.size(0)\n",
        "    train_loss /= len(mnist_train)\n",
        "    train_acc = correct / len(mnist_train)\n",
        "    print(f\"Epoch {epoch+1}: Train loss {train_loss:.4f}, Train accuracy {train_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "def validate_model(model, epochs = 1, device=\"cpu\"):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  for epoch in range(epochs):\n",
        "    correct = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for xb, yb in DataLoader(mnist_test, batch_size=64, shuffle=True):\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        preds = model(xb)\n",
        "        loss = F.cross_entropy(preds, yb)\n",
        "        val_loss += loss.item() * xb.size(0)\n",
        "        correct += (preds.argmax(dim=1) == yb).sum().item()\n",
        "    val_acc = correct / len(mnist_test)\n",
        "    val_loss /= len(mnist_test)\n",
        "    print(f\"Epoch {epoch+1}: Val loss {val_loss:.4f}, Val accuracy {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "def train_and_validate(model, optimizer, epochs=4, device=\"cpu\"):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    for xb, yb in DataLoader(mnist_train, batch_size=64, shuffle=True):\n",
        "      optimizer.zero_grad()\n",
        "      xb = xb.to(device)\n",
        "      yb = yb.to(device)\n",
        "      preds = model(xb)\n",
        "      loss = F.cross_entropy(preds, yb)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_correct += (preds.argmax(dim=1) == yb).sum().item()\n",
        "      train_loss += loss.item() * xb.size(0)\n",
        "    train_loss /= len(mnist_train)\n",
        "    train_acc = train_correct / len(mnist_train)\n",
        "    print(f\"Epoch {epoch+1}: Train loss {train_loss:.4f}, Train accuracy {train_acc:.4f}\")\n",
        "    val_correct = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for xb, yb in DataLoader(mnist_test, batch_size=64, shuffle=True):\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        preds = model(xb)\n",
        "        loss = F.cross_entropy(preds, yb)\n",
        "        val_loss += loss.item() * xb.size(0)\n",
        "        val_correct += (preds.argmax(dim=1) == yb).sum().item()\n",
        "    val_acc = val_correct / len(mnist_test)\n",
        "    val_loss /= len(mnist_test)\n",
        "    print(f\"Epoch {epoch+1}: Val loss {val_loss:.4f}, Val accuracy {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "5Gir9cpD0a1z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_model(simple_cnn, torch.optim.Adam(simple_cnn.parameters(), lr=0.01), epochs=5, device=\"cuda\")\n",
        "#validate_model(simple_cnn, epochs=5, device=\"cuda\")\n",
        "train_and_validate(simple_cnn, torch.optim.Adam(simple_cnn.parameters(), lr=0.01), epochs=5, device=\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I04Il2tU0e9m",
        "outputId": "20b061d6-a836-4e0e-ff41-6a07119449ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train loss 0.0770, Train accuracy 0.9770\n",
            "Epoch 1: Val loss 0.0876, Val accuracy 0.9770\n",
            "Epoch 2: Train loss 0.0786, Train accuracy 0.9772\n",
            "Epoch 2: Val loss 0.1103, Val accuracy 0.9682\n",
            "Epoch 3: Train loss 0.0815, Train accuracy 0.9748\n",
            "Epoch 3: Val loss 0.0947, Val accuracy 0.9712\n",
            "Epoch 4: Train loss 0.0772, Train accuracy 0.9773\n",
            "Epoch 4: Val loss 0.0861, Val accuracy 0.9747\n",
            "Epoch 5: Train loss 0.0755, Train accuracy 0.9778\n",
            "Epoch 5: Val loss 0.0908, Val accuracy 0.9759\n"
          ]
        }
      ]
    }
  ]
}